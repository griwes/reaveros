/*
 * Copyright © 2021-2022 Michał 'Griwes' Dominiak
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "__config"
#include "concepts"
#include "cstddef"
#include "cstdint"
#include "type_traits"
#include "version"

__ROSESTD_OPEN

enum class memory_order : int
{
    relaxed = __ATOMIC_RELAXED,
    consume = __ATOMIC_CONSUME,
    acquire = __ATOMIC_ACQUIRE,
    release = __ATOMIC_RELEASE,
    acq_rel = __ATOMIC_ACQ_REL,
    seq_cst = __ATOMIC_SEQ_CST
};

inline constexpr memory_order memory_order_relaxed = memory_order::relaxed;
inline constexpr memory_order memory_order_consume = memory_order::consume;
inline constexpr memory_order memory_order_acquire = memory_order::acquire;
inline constexpr memory_order memory_order_release = memory_order::release;
inline constexpr memory_order memory_order_acq_rel = memory_order::acq_rel;
inline constexpr memory_order memory_order_seq_cst = memory_order::seq_cst;

template<typename _T>
_T kill_dependency(_T __y) noexcept;

#ifdef __ROSESTD_TETING

#undef ATOMIC_BOOL_LOCK_FREE
#undef ATOMIC_CHAR_LOCK_FREE
#undef ATOMIC_CHAR8_T_LOCK_FREE
#undef ATOMIC_CHAR16_T_LOCK_FREE
#undef ATOMIC_CHAR32_T_LOCK_FREE
#undef ATOMIC_WCHAR_T_LOCK_FREE
#undef ATOMIC_SHORT_LOCK_FREE
#undef ATOMIC_INT_LOCK_FREE
#undef ATOMIC_LONG_LOCK_FREE
#undef ATOMIC_LLONG_LOCK_FREE
#undef ATOMIC_POINTER_LOCK_FREE

#else

#define ATOMIC_BOOL_LOCK_FREE 2
#define ATOMIC_CHAR_LOCK_FREE 2
#define ATOMIC_CHAR8_T_LOCK_FREE 2
#define ATOMIC_CHAR16_T_LOCK_FREE 2
#define ATOMIC_CHAR32_T_LOCK_FREE 2
#define ATOMIC_WCHAR_T_LOCK_FREE 2
#define ATOMIC_SHORT_LOCK_FREE 2
#define ATOMIC_INT_LOCK_FREE 2
#define ATOMIC_LONG_LOCK_FREE 2
#define ATOMIC_LLONG_LOCK_FREE 2
#define ATOMIC_POINTER_LOCK_FREE 2

#endif

template<typename _T>
struct atomic_ref;
template<typename _T>
struct atomic_ref<_T *>;

template<typename _T>
struct __atomic_base_lock_free
{
    static const constexpr bool is_always_lock_free = true;

    __atomic_base_lock_free() noexcept(is_nothrow_default_constructible_v<_T>) : __val()
    {
    }

    __atomic_base_lock_free(_T __t) : __val(static_cast<_T &&>(__t))
    {
    }

    alignas(sizeof(_T)) _T __val;
};

template<typename _T>
_T __cxx_atomic_load(memory_order __order, const volatile __atomic_base_lock_free<_T> * __a)
{
    _T __ret;
    __atomic_load(&__a->__val, &__ret, static_cast<int>(__order));
    return __ret;
}

template<typename _T>
void __cxx_atomic_store(memory_order __order, volatile __atomic_base_lock_free<_T> * __a, _T __val)
{
    __atomic_store(&__a->__val, &__val, static_cast<int>(__order));
}

template<typename _T>
_T __cxx_atomic_exchange(memory_order __order, volatile __atomic_base_lock_free<_T> * __a, _T __value)
{
    _T __ret;
    __atomic_exchange(&__a->__val, &__value, &__ret, static_cast<int>(__order));
    return __ret;
}

template<typename _T>
bool __cxx_atomic_cmpxchg_weak(
    memory_order __success,
    memory_order __failure,
    volatile __atomic_base_lock_free<_T> * __a,
    _T * __expected,
    _T __desired)
{
    return __atomic_compare_exchange(
        &__a->__val, __expected, &__desired, true, static_cast<int>(__success), static_cast<int>(__failure));
}

template<typename _T>
bool __cxx_atomic_cmpxchg_strong(
    memory_order __success,
    memory_order __failure,
    volatile __atomic_base_lock_free<_T> * __a,
    _T * __expected,
    _T __desired)
{
    return __atomic_compare_exchange(
        &__a->__val, __expected, &__desired, false, static_cast<int>(__success), static_cast<int>(__failure));
}

template<typename _T>
_T __cxx_atomic_fetch_add(memory_order __order, volatile __atomic_base_lock_free<_T> * __a, _T __rhs)
{
    return __atomic_fetch_add(&__a->__val, __rhs, static_cast<int>(__order));
}

template<typename _T>
_T __cxx_atomic_fetch_sub(memory_order __order, volatile __atomic_base_lock_free<_T> * __a, _T __rhs)
{
    return __atomic_fetch_sub(&__a->__val, __rhs, static_cast<int>(__order));
}

template<typename _T>
struct __atomic_base_non_lock_free
{
    static const constexpr bool is_always_lock_free = false;
};

template<typename _T>
struct __atomic_base_selector;

template<typename _T>
requires(__atomic_always_lock_free(sizeof(_T), 0)) struct __atomic_base_selector<_T>
{
    using type = __atomic_base_lock_free<_T>;
};

template<typename _T>
requires(!__atomic_always_lock_free(sizeof(_T), 0)) struct __atomic_base_selector<_T>
{
    using type = __atomic_base_non_lock_free<_T>;
};

template<typename _T>
using __atomic_base_impl = typename __atomic_base_selector<_T>::type;

inline memory_order __remap_failure_order(memory_order __order)
{
    switch (__order)
    {
        case memory_order_acq_rel:
            return memory_order_acquire;
        case memory_order_release:
            return memory_order_relaxed;
        default:
            return __order;
    }
}

template<typename _T>
class __atomic_base
{
public:
    using value_type = _T;

    static_assert(is_trivially_copyable_v<_T>);
    static_assert(is_copy_constructible_v<_T>);
    static_assert(is_move_constructible_v<_T>);
    static_assert(is_copy_assignable_v<_T>);
    static_assert(is_move_assignable_v<_T>);

    bool is_lock_free() const volatile noexcept
    {
        return __atomic_base_impl<_T>::is_always_lock_free;
    }

    bool is_lock_free() const noexcept
    {
        return __atomic_base_impl<_T>::is_always_lock_free;
    }

    constexpr __atomic_base() noexcept(is_nothrow_default_constructible_v<_T>) = default;

    constexpr __atomic_base(_T __val) noexcept : __impl(static_cast<_T &&>(__val))
    {
    }

    __atomic_base(const __atomic_base &) = delete;
    __atomic_base & operator=(const __atomic_base &) = delete;
    __atomic_base & operator=(const __atomic_base &) volatile = delete;

    _T exchange(_T __value, memory_order __order = memory_order::seq_cst) volatile noexcept
    {
        return __cxx_atomic_exchange(__order, &__impl, __value);
    }

    _T exchange(_T __value, memory_order __order = memory_order::seq_cst) noexcept
    {
        return __cxx_atomic_exchange(__order, &__impl, __value);
    }

    bool compare_exchange_weak(
        _T & __expected,
        _T __desired,
        memory_order __success,
        memory_order __failure) volatile noexcept
    {
        return __cxx_atomic_cmpxchg_weak(__success, __failure, &__impl, &__expected, __desired);
    }

    bool compare_exchange_weak(
        _T & __expected,
        _T __desired,
        memory_order __success,
        memory_order __failure) noexcept
    {
        return __cxx_atomic_cmpxchg_weak(__success, __failure, &__impl, &__expected, __desired);
    }

    bool compare_exchange_strong(
        _T & __expected,
        _T __desired,
        memory_order __success,
        memory_order __failure) volatile noexcept
    {
        return __cxx_atomic_cmpxchg_strong(__success, __failure, &__impl, &__expected, __desired);
    }

    bool compare_exchange_strong(
        _T & __expected,
        _T __desired,
        memory_order __success,
        memory_order __failure) noexcept
    {
        return __cxx_atomic_cmpxchg_strong(__success, __failure, &__impl, &__expected, __desired);
    }

    bool compare_exchange_weak(
        _T & __expected,
        _T __desired,
        memory_order __order = memory_order::seq_cst) volatile noexcept
    {
        auto __success = __order;
        auto __failure = __remap_failure_order(__order);

        return compare_exchange_weak(__expected, __desired, __success, __failure);
    }

    bool compare_exchange_weak(
        _T & __expected,
        _T __desired,
        memory_order __order = memory_order::seq_cst) noexcept
    {
        auto __success = __order;
        auto __failure = __remap_failure_order(__order);

        return compare_exchange_weak(__expected, __desired, __success, __failure);
    }

    bool compare_exchange_strong(
        _T & __expected,
        _T __desired,
        memory_order __order = memory_order::seq_cst) volatile noexcept
    {
        auto __success = __order;
        auto __failure = __remap_failure_order(__order);

        return compare_exchange_strong(__expected, __desired, __success, __failure);
    }

    bool compare_exchange_strong(
        _T & __expected,
        _T __desired,
        memory_order __order = memory_order::seq_cst) noexcept
    {
        auto __success = __order;
        auto __failure = __remap_failure_order(__order);

        return compare_exchange_strong(__expected, __desired, __success, __failure);
    }

    _T load(memory_order __order = memory_order::seq_cst) const volatile noexcept
    {
        return __cxx_atomic_load(__order, &__impl);
    }

    _T load(memory_order __order = memory_order::seq_cst) const noexcept
    {
        return __cxx_atomic_load(__order, &__impl);
    }

    operator _T() const volatile noexcept
    {
        return load();
    }

    operator _T() const noexcept
    {
        return load();
    }

    void store(_T __new, memory_order __order = memory_order::seq_cst) volatile noexcept
    {
        __cxx_atomic_store(__order, &__impl, __new);
    }

    void store(_T __new, memory_order __order = memory_order::seq_cst) noexcept
    {
        __cxx_atomic_store(__order, &__impl, __new);
    }

    _T operator=(_T __val) volatile noexcept
    {
        store(__val);
        return __val;
    }

    _T operator=(_T __val) noexcept
    {
        store(__val);
        return __val;
    }

    void wait(_T, memory_order = memory_order::seq_cst) const volatile noexcept;
    void wait(_T, memory_order = memory_order::seq_cst) const noexcept;
    void notify_one() volatile noexcept;
    void notify_one() noexcept;
    void notify_all() volatile noexcept;
    void notify_all() noexcept;

protected:
    __atomic_base_impl<_T> __impl;
};

template<typename _T>
class atomic : public __atomic_base<_T>
{
    using __base = __atomic_base<_T>;

public:
    using __base::__base;
    using __base::operator=;
};

template<typename _T>
requires integral<_T>
class atomic<_T> : public __atomic_base<_T>
{
    using __base = __atomic_base<_T>;

public:
    using __base::__base;
    using __base::operator=;

    using difference_type = _T;

    _T fetch_add(_T __val, memory_order __order = memory_order::seq_cst) volatile noexcept
    {
        return __cxx_atomic_fetch_add(__order, &this->__impl, __val);
    }

    _T fetch_add(_T __val, memory_order __order = memory_order::seq_cst) noexcept
    {
        return __cxx_atomic_fetch_add(__order, &this->__impl, __val);
    }

    _T fetch_sub(_T __val, memory_order __order = memory_order::seq_cst) volatile noexcept
    {
        return __cxx_atomic_fetch_sub(__order, &this->__impl, __val);
    }

    _T fetch_sub(_T __val, memory_order __order = memory_order::seq_cst) noexcept
    {
        return __cxx_atomic_fetch_sub(__order, &this->__impl, __val);
    }

    _T fetch_and(_T, memory_order = memory_order::seq_cst) volatile noexcept;
    _T fetch_and(_T, memory_order = memory_order::seq_cst) noexcept;
    _T fetch_or(_T, memory_order = memory_order::seq_cst) volatile noexcept;
    _T fetch_or(_T, memory_order = memory_order::seq_cst) noexcept;
    _T fetch_xor(_T, memory_order = memory_order::seq_cst) volatile noexcept;
    _T fetch_xor(_T, memory_order = memory_order::seq_cst) noexcept;

    _T operator++(int) volatile noexcept
    {
        return fetch_add(1);
    }

    _T operator++(int) noexcept
    {
        return fetch_add(1);
    }

    _T operator--(int) volatile noexcept
    {
        return fetch_sub(1);
    }

    _T operator--(int) noexcept
    {
        return fetch_sub(1);
    }

    _T operator++() volatile noexcept
    {
        return fetch_add(1) + 1;
    }

    _T operator++() noexcept
    {
        return fetch_add(1) + 1;
    }

    _T operator--() volatile noexcept
    {
        return fetch_sub(1) - 1;
    }

    _T operator--() noexcept
    {
        return fetch_sub(1) - 1;
    }

    _T operator+=(_T) volatile noexcept;
    _T operator+=(_T) noexcept;
    _T operator-=(_T) volatile noexcept;
    _T operator-=(_T) noexcept;
    _T operator&=(_T) volatile noexcept;
    _T operator&=(_T) noexcept;
    _T operator|=(_T) volatile noexcept;
    _T operator|=(_T) noexcept;
    _T operator^=(_T) volatile noexcept;
    _T operator^=(_T) noexcept;
};

template<typename _T>
requires floating_point<_T>
class atomic<_T> : public __atomic_base<_T>
{
    using __base = __atomic_base<_T>;

public:
    using __base::__base;
    using __base::operator=;

    using difference_type = _T;

    _T fetch_add(_T, memory_order = memory_order::seq_cst) volatile noexcept;
    _T fetch_add(_T, memory_order = memory_order::seq_cst) noexcept;
    _T fetch_sub(_T, memory_order = memory_order::seq_cst) volatile noexcept;
    _T fetch_sub(_T, memory_order = memory_order::seq_cst) noexcept;

    _T operator+=(_T) volatile noexcept;
    _T operator+=(_T) noexcept;
    _T operator-=(_T) volatile noexcept;
    _T operator-=(_T) noexcept;
};

template<typename _T>
class atomic<_T *> : public __atomic_base<_T *>
{
    using __base = __atomic_base<_T>;

public:
    using __base::__base;
    using __base::operator=;

    using difference_type = ptrdiff_t;

    _T * fetch_add(ptrdiff_t, memory_order = memory_order::seq_cst) volatile noexcept;
    _T * fetch_add(ptrdiff_t, memory_order = memory_order::seq_cst) noexcept;
    _T * fetch_sub(ptrdiff_t, memory_order = memory_order::seq_cst) volatile noexcept;
    _T * fetch_sub(ptrdiff_t, memory_order = memory_order::seq_cst) noexcept;

    _T * operator++(int) volatile noexcept;
    _T * operator++(int) noexcept;
    _T * operator--(int) volatile noexcept;
    _T * operator--(int) noexcept;
    _T * operator++() volatile noexcept;
    _T * operator++() noexcept;
    _T * operator--() volatile noexcept;
    _T * operator--() noexcept;
    _T * operator+=(ptrdiff_t) volatile noexcept;
    _T * operator+=(ptrdiff_t) noexcept;
    _T * operator-=(ptrdiff_t) volatile noexcept;
    _T * operator-=(ptrdiff_t) noexcept;
};

template<typename _T>
bool atomic_is_lock_free(const volatile atomic<_T> *) noexcept;
template<typename _T>
bool atomic_is_lock_free(const atomic<_T> *) noexcept;
template<typename _T>
void atomic_store(volatile atomic<_T> *, typename atomic<_T>::value_type) noexcept;
template<typename _T>
void atomic_store(atomic<_T> *, typename atomic<_T>::value_type) noexcept;
template<typename _T>
void atomic_store_explicit(volatile atomic<_T> *, typename atomic<_T>::value_type, memory_order) noexcept;
template<typename _T>
void atomic_store_explicit(atomic<_T> *, typename atomic<_T>::value_type, memory_order) noexcept;
template<typename _T>
_T atomic_load(const volatile atomic<_T> *) noexcept;
template<typename _T>
_T atomic_load(const atomic<_T> *) noexcept;
template<typename _T>
_T atomic_load_explicit(const volatile atomic<_T> *, memory_order) noexcept;
template<typename _T>
_T atomic_load_explicit(const atomic<_T> *, memory_order) noexcept;
template<typename _T>
_T atomic_exchange(volatile atomic<_T> *, typename atomic<_T>::value_type) noexcept;
template<typename _T>
_T atomic_exchange(atomic<_T> *, typename atomic<_T>::value_type) noexcept;
template<typename _T>
_T atomic_exchange_explicit(volatile atomic<_T> *, typename atomic<_T>::value_type, memory_order) noexcept;
template<typename _T>
_T atomic_exchange_explicit(atomic<_T> *, typename atomic<_T>::value_type, memory_order) noexcept;
template<typename _T>
bool atomic_compare_exchange_weak(
    volatile atomic<_T> *,
    typename atomic<_T>::value_type *,
    typename atomic<_T>::value_type) noexcept;
template<typename _T>
bool atomic_compare_exchange_weak(
    atomic<_T> *,
    typename atomic<_T>::value_type *,
    typename atomic<_T>::value_type) noexcept;
template<typename _T>
bool atomic_compare_exchange_strong(
    volatile atomic<_T> *,
    typename atomic<_T>::value_type *,
    typename atomic<_T>::value_type) noexcept;
template<typename _T>
bool atomic_compare_exchange_strong(
    atomic<_T> *,
    typename atomic<_T>::value_type *,
    typename atomic<_T>::value_type) noexcept;
template<typename _T>
bool atomic_compare_exchange_weak_explicit(
    volatile atomic<_T> *,
    typename atomic<_T>::value_type *,
    typename atomic<_T>::value_type,
    memory_order,
    memory_order) noexcept;
template<typename _T>
bool atomic_compare_exchange_weak_explicit(
    atomic<_T> *,
    typename atomic<_T>::value_type *,
    typename atomic<_T>::value_type,
    memory_order,
    memory_order) noexcept;
template<typename _T>
bool atomic_compare_exchange_strong_explicit(
    volatile atomic<_T> *,
    typename atomic<_T>::value_type *,
    typename atomic<_T>::value_type,
    memory_order,
    memory_order) noexcept;
template<typename _T>
bool atomic_compare_exchange_strong_explicit(
    atomic<_T> *,
    typename atomic<_T>::value_type *,
    typename atomic<_T>::value_type,
    memory_order,
    memory_order) noexcept;

template<typename _T>
_T atomic_fetch_add(volatile atomic<_T> *, typename atomic<_T>::difference_type) noexcept;
template<typename _T>
_T atomic_fetch_add(atomic<_T> *, typename atomic<_T>::difference_type) noexcept;
template<typename _T>
_T atomic_fetch_add_explicit(
    volatile atomic<_T> *,
    typename atomic<_T>::difference_type,
    memory_order) noexcept;
template<typename _T>
_T atomic_fetch_add_explicit(atomic<_T> *, typename atomic<_T>::difference_type, memory_order) noexcept;
template<typename _T>
_T atomic_fetch_sub(volatile atomic<_T> *, typename atomic<_T>::difference_type) noexcept;
template<typename _T>
_T atomic_fetch_sub(atomic<_T> *, typename atomic<_T>::difference_type) noexcept;
template<typename _T>
_T atomic_fetch_sub_explicit(
    volatile atomic<_T> *,
    typename atomic<_T>::difference_type,
    memory_order) noexcept;
template<typename _T>
_T atomic_fetch_sub_explicit(atomic<_T> *, typename atomic<_T>::difference_type, memory_order) noexcept;
template<typename _T>
_T atomic_fetch_and(volatile atomic<_T> *, typename atomic<_T>::value_type) noexcept;
template<typename _T>
_T atomic_fetch_and(atomic<_T> *, typename atomic<_T>::value_type) noexcept;
template<typename _T>
_T atomic_fetch_and_explicit(volatile atomic<_T> *, typename atomic<_T>::value_type, memory_order) noexcept;
template<typename _T>
_T atomic_fetch_and_explicit(atomic<_T> *, typename atomic<_T>::value_type, memory_order) noexcept;
template<typename _T>
_T atomic_fetch_or(volatile atomic<_T> *, typename atomic<_T>::value_type) noexcept;
template<typename _T>
_T atomic_fetch_or(atomic<_T> *, typename atomic<_T>::value_type) noexcept;
template<typename _T>
_T atomic_fetch_or_explicit(volatile atomic<_T> *, typename atomic<_T>::value_type, memory_order) noexcept;
template<typename _T>
_T atomic_fetch_or_explicit(atomic<_T> *, typename atomic<_T>::value_type, memory_order) noexcept;
template<typename _T>
_T atomic_fetch_xor(volatile atomic<_T> *, typename atomic<_T>::value_type) noexcept;
template<typename _T>
_T atomic_fetch_xor(atomic<_T> *, typename atomic<_T>::value_type) noexcept;
template<typename _T>
_T atomic_fetch_xor_explicit(volatile atomic<_T> *, typename atomic<_T>::value_type, memory_order) noexcept;
template<typename _T>
_T atomic_fetch_xor_explicit(atomic<_T> *, typename atomic<_T>::value_type, memory_order) noexcept;

template<typename _T>
void atomic_wait(const volatile atomic<_T> *, typename atomic<_T>::value_type);
template<typename _T>
void atomic_wait(const atomic<_T> *, typename atomic<_T>::value_type);
template<typename _T>
void atomic_wait_explicit(const volatile atomic<_T> *, typename atomic<_T>::value_type, memory_order);
template<typename _T>
void atomic_wait_explicit(const atomic<_T> *, typename atomic<_T>::value_type, memory_order);
template<typename _T>
void atomic_notify_one(volatile atomic<_T> *);
template<typename _T>
void atomic_notify_one(atomic<_T> *);
template<typename _T>
void atomic_notify_all(volatile atomic<_T> *);
template<typename _T>
void atomic_notify_all(atomic<_T> *);

// [atomics.alias], type aliases
using atomic_bool = atomic<bool>;
using atomic_char = atomic<char>;
using atomic_schar = atomic<signed char>;
using atomic_uchar = atomic<unsigned char>;
using atomic_short = atomic<short>;
using atomic_ushort = atomic<unsigned short>;
using atomic_int = atomic<int>;
using atomic_uint = atomic<unsigned int>;
using atomic_long = atomic<long>;
using atomic_ulong = atomic<unsigned long>;
using atomic_llong = atomic<long long>;
using atomic_ullong = atomic<unsigned long long>;
using atomic_char8_t = atomic<char8_t>;
using atomic_char16_t = atomic<char16_t>;
using atomic_char32_t = atomic<char32_t>;
using atomic_wchar_t = atomic<wchar_t>;

using atomic_int8_t = atomic<int8_t>;
using atomic_uint8_t = atomic<uint8_t>;
using atomic_int16_t = atomic<int16_t>;
using atomic_uint16_t = atomic<uint16_t>;
using atomic_int32_t = atomic<int32_t>;
using atomic_uint32_t = atomic<uint32_t>;
using atomic_int64_t = atomic<int64_t>;
using atomic_uint64_t = atomic<uint64_t>;

using atomic_int_least8_t = atomic<int_least8_t>;
using atomic_uint_least8_t = atomic<uint_least8_t>;
using atomic_int_least16_t = atomic<int_least16_t>;
using atomic_uint_least16_t = atomic<uint_least16_t>;
using atomic_int_least32_t = atomic<int_least32_t>;
using atomic_uint_least32_t = atomic<uint_least32_t>;
using atomic_int_least64_t = atomic<int_least64_t>;
using atomic_uint_least64_t = atomic<uint_least64_t>;

using atomic_int_fast8_t = atomic<int_fast8_t>;
using atomic_uint_fast8_t = atomic<uint_fast8_t>;
using atomic_int_fast16_t = atomic<int_fast16_t>;
using atomic_uint_fast16_t = atomic<uint_fast16_t>;
using atomic_int_fast32_t = atomic<int_fast32_t>;
using atomic_uint_fast32_t = atomic<uint_fast32_t>;
using atomic_int_fast64_t = atomic<int_fast64_t>;
using atomic_uint_fast64_t = atomic<uint_fast64_t>;

using atomic_intptr_t = atomic<intptr_t>;
using atomic_uintptr_t = atomic<uintptr_t>;
using atomic_size_t = atomic<size_t>;
using atomic_ptrdiff_t = atomic<ptrdiff_t>;
using atomic_intmax_t = atomic<intmax_t>;
using atomic_uintmax_t = atomic<uintmax_t>;

using atomic_signed_lock_free = atomic<int8_t>;
using atomic_unsigned_lock_free = atomic<uint8_t>;

// [atomics.flag], flag type and operations
struct atomic_flag;

bool atomic_flag_test(const volatile atomic_flag *) noexcept;
bool atomic_flag_test(const atomic_flag *) noexcept;
bool atomic_flag_test_explicit(const volatile atomic_flag *, memory_order) noexcept;
bool atomic_flag_test_explicit(const atomic_flag *, memory_order) noexcept;
bool atomic_flag_test_and_set(volatile atomic_flag *) noexcept;
bool atomic_flag_test_and_set(atomic_flag *) noexcept;
bool atomic_flag_test_and_set_explicit(volatile atomic_flag *, memory_order) noexcept;
bool atomic_flag_test_and_set_explicit(atomic_flag *, memory_order) noexcept;
void atomic_flag_clear(volatile atomic_flag *) noexcept;
void atomic_flag_clear(atomic_flag *) noexcept;
void atomic_flag_clear_explicit(volatile atomic_flag *, memory_order) noexcept;
void atomic_flag_clear_explicit(atomic_flag *, memory_order) noexcept;

void atomic_flag_wait(const volatile atomic_flag *, bool) noexcept;
void atomic_flag_wait(const atomic_flag *, bool) noexcept;
void atomic_flag_wait_explicit(const volatile atomic_flag *, bool, memory_order) noexcept;
void atomic_flag_wait_explicit(const atomic_flag *, bool, memory_order) noexcept;
void atomic_flag_notify_one(volatile atomic_flag *) noexcept;
void atomic_flag_notify_one(atomic_flag *) noexcept;
void atomic_flag_notify_all(volatile atomic_flag *) noexcept;
void atomic_flag_notify_all(atomic_flag *) noexcept;

extern "C" void atomic_thread_fence(memory_order) noexcept;
extern "C" void atomic_signal_fence(memory_order) noexcept;

__ROSESTD_CLOSE

// vim: ft=cpp
